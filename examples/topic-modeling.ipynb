{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from contextualized_topic_models.models.cotm import COTM\n",
    "from contextualized_topic_models.utils.data_preparation import to_bow\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from contextualized_topic_models.datasets.dataset import LMTopicDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = os.path.join('../contextualized_topic_models/data/gnews', 'vocab.pkl')\n",
    "vocab = json.load(open(vocab, 'r'))\n",
    "idx2token = {v: k for (k, v) in vocab.items()}\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "train = np.load(os.path.join('../contextualized_topic_models/data/gnews', 'train.txt.pkl'), encoding='latin1', allow_pickle=True)\n",
    "train_bow = to_bow(train, vocab_size)\n",
    "\n",
    "with open(\"../contextualized_topic_models/data/gnews/bert_embeddings_gnews\", \"rb\") as filino:\n",
    "    train_bert = pickle.load(filino)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "training_data = LMTopicDataset(train_bow, train_bert, idx2token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Settings: \n",
      "               N Components: 50\n",
      "               Topic Prior Mean: 0.0\n",
      "               Topic Prior Variance: 0.98\n",
      "               Model Type: prodLDA\n",
      "               Hidden Sizes: (100,)\n",
      "               Activation: softplus\n",
      "               Dropout: 0.2\n",
      "               Learn Priors: True\n",
      "               Learning Rate: 0.002\n",
      "               Momentum: 0.99\n",
      "               Reduce On Plateau: False\n",
      "               Save Dir: None\n",
      "Epoch: [1/2]\tSamples: [11108/22216]\tTrain Loss: 92.30986263067722\tTime: 0:00:03.105151\n",
      "Epoch: [2/2]\tSamples: [22216/22216]\tTrain Loss: 81.17217109853259\tTime: 0:00:02.737545\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "cotm = COTM(input_size=vocab_size, bert_input_size=len(train_bert[0]),  inferencetype=\"contextual\",\n",
    "                n_components=50, model_type=\"prodLDA\",\n",
    "              hidden_sizes=(100, ), activation='softplus', dropout=0.2,\n",
    "              learn_priors=True, batch_size=200, lr=2e-3, momentum=0.99,\n",
    "              solver='adam', num_epochs=2, reduce_on_plateau=False, \n",
    "                  num_data_loader_workers=0)\n",
    "\n",
    "cotm.fit(training_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[['andreas', 'san', 'flying', 'station', 'mobile'],\n ['black', 'friday', 'deal', 'lumia', 'best'],\n ['seth', 'kanye', 'west', 'james', 'franco'],\n ['men', 'wearhouse', 'jos', 'bank', 'bid'],\n ['murder', 'child', 'daughter', 'guilty', 'hospital'],\n ['beltran', 'group', 'steubenville', 'rape', 'mourinho'],\n ['xbox', 'seek', 'held', 'console', 'spacex'],\n ['storm', 'winter', 'travel', 'lumia', 'weather'],\n ['jennifer', 'change', 'pope', 'rate', 'warns'],\n ['troop', 'central', 'republic', 'france', 'pope'],\n ['heart', 'woman', 'secretly', 'fed', 'treasury'],\n ['lumia', 'nokia', 'ice', 'microsoft', 'motorola'],\n ['december', 'coming', 'andreas', 'grand', 'theft'],\n ['heart', 'envoy', 'author', 'joseph', 'pain'],\n ['salmond', 'seahorse', 'independence', 'arrested', 'whopping'],\n ['week', 'bronco', 'peyton', 'raider', 'loss'],\n ['xbox', 'auto', 'theft', 'microsoft', 'android'],\n ['kardashian', 'german', 'kim', 'reaction', 'spoof'],\n ['kim', 'kanye', 'west', 'kardashian', 'bon'],\n ['china', 'zone', 'flouts', 'shump', 'thyself'],\n ['swift', 'william', 'prince', 'jovi', 'lakers'],\n ['kanye', 'west', 'bound', 'franco', 'parody'],\n ['sex', 'hewitt', 'urge', 'baby', 'watkins'],\n ['form', 'coalition', 'porn', 'dna', 'viking'],\n ['msnbc', 'violence', 'iraq', 'alec', 'force'],\n ['ian', 'daughter', 'lostprophets', 'flu', 'nurse'],\n ['star', 'dancing', 'cyber', 'monday', 'deal'],\n ['chelsea', 'basel', 'case', 'adam', 'conference'],\n ['dancing', 'star', 'call', 'review', 'washington'],\n ['west', 'kanye', 'nba', 'bryant', 'thanksgivukkah'],\n ['net', 'wny', 'ravaged', 'joseph', 'saint'],\n ['thanksgiving', 'macy', 'balloon', 'parade', 'girl'],\n ['google', 'bbm', 'chrome', 'blackberry', 'search'],\n ['thanksgiving', 'parade', 'day', 'hanukkah', 'week'],\n ['attack', 'berlusconi', 'family', 'senate', 'habit'],\n ['thanksgivukkah', 'free', 'basel', 'niu', 'preview'],\n ['nativity', 'league', 'chelsea', 'jose', 'basel'],\n ['thanksgiving', 'day', 'parade', 'storm', 'macy'],\n ['storm', 'travel', 'comet', 'sun', 'bad'],\n ['frozen', 'comet', 'ison', 'pill', 'nhl'],\n ['role', 'flouts', 'mailbag', 'christ', 'friday'],\n ['lakers', 'phone', 'kanye', 'bbm', 'blackberry'],\n ['star', 'dancing', 'season', 'day', 'riley'],\n ['communism', 'loathe', 'thanksgivukkah', 'mailbag', 'task'],\n ['flouts', 'leappad', 'titled', 'mashing', 'edging'],\n ['greek', 'player', 'reportedly', 'hiv', 'game'],\n ['sale', 'google', 'frozen', 'xbox', 'family'],\n ['nokia', 'glass', 'moto', 'blackberry', 'lumia'],\n ['jovi', 'prince', 'william', 'bon', 'jon'],\n ['jos', 'men', 'wearhouse', 'bank', 'frozen']]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "cotm.get_topic_lists(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluate the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from contextualized_topic_models.evaluation.measures import TopicDiversity, CoherenceNPMI,\\\n",
    "    CoherenceWordEmbeddings,RBO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.5968"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 7
    }
   ],
   "source": [
    "td = TopicDiversity(cotm.get_topic_lists(25))\n",
    "td.score(topk=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.015902484681825074"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "rbo = RBO(cotm.get_topic_lists(10))\n",
    "rbo.score()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[['google', 'nokia', 'glass', 'lumia', 'chromebooks'],\n ['theft', 'andreas', 'grand', 'mobile', 'san'],\n ['white', 'scotland', 'aid', 'church', 'raf'],\n ['nokia', 'window', 'google', 'microsoft', 'lumia'],\n ['birth', 'girl', 'hospital', 'texas', 'nurse'],\n ['andreas', 'san', 'mobile', 'theft', 'grand'],\n ['kanye', 'kim', 'west', 'james', 'kardashian'],\n ['friday', 'black', 'jennifer', 'free', 'launch'],\n ['bronco', 'welker', 'wes', 'cowboy', 'week'],\n ['nigella', 'irs', 'woman', 'child', 'guilty'],\n ['nokia', 'lumia', 'stock', 'att', 'app'],\n ['skyline', 'bridging', 'cosmetic', 'bribe', 'curve'],\n ['storm', 'air', 'typhoon', 'seahawks', 'east'],\n ['berlusconi', 'originally', 'merkel', 'scottish', 'patent'],\n ['jovi', 'independence', 'republic', 'unveils', 'plan'],\n ['minute', 'seahawks', 'storm', 'arizona', 'syria'],\n ['microsoft', 'morning', 'woman', 'nokia', 'effective'],\n ['decimate', 'discontinue', 'seized', 'expletive', 'bridging'],\n ['xbox', 'microsoft', 'disc', 'nokia', 'amber'],\n ['amid', 'gm', 'common', 'skyline', 'activity'],\n ['refugee', 'air', 'comet', 'china', 'disputed'],\n ['prince', 'taylor', 'bon', 'william', 'jovi'],\n ['uk', 'dallas', 'anaheim', 'homefront', 'spacex'],\n ['china', 'zone', 'bank', 'earnings', 'tax'],\n ['kanye', 'west', 'seth', 'bound', 'rogen'],\n ['independent', 'independence', 'bribe', 'salmond', 'scotland'],\n ['lumia', 'nokia', 'release', 'company', 'sold'],\n ['army', 'nigella', 'shock', 'thai', 'mach'],\n ['strong', 'super', 'mediocre', 'moto', 'iran'],\n ['independence', 'bronco', 'scottish', 'michigan', 'nike'],\n ['year', 'seahawks', 'sing', 'girl', 'alec'],\n ['court', 'group', 'berlusconi', 'thurmond', 'discredit'],\n ['zone', 'irs', 'china', 'tax', 'air'],\n ['stalking', 'mediocre', 'originally', 'eas', 'fairfield'],\n ['fall', 'sriracha', 'suspended', 'drop', 'protest'],\n ['aarushi', 'rape', 'lostprophets', 'admits', 'child'],\n ['travel', 'storm', 'ice', 'packer', 'frozen'],\n ['nativity', 'black', 'friday', 'nike', 'slave'],\n ['friday', 'black', 'thanksgiving', 'day', 'shopping'],\n ['mildly', 'kim', 'famer', 'knowing', 'skyline'],\n ['star', 'thanksgiving', 'tv', 'disney', 'nhl'],\n ['lion', 'packer', 'console', 'throw', 'baby'],\n ['woman', 'champion', 'league', 'dead', 'black'],\n ['watkins', 'guilty', 'pleads', 'murder', 'child'],\n ['bank', 'jos', 'wearhouse', 'bryant', 'offer'],\n ['moto', 'bbm', 'motorola', 'andreas', 'nokia'],\n ['sandy', 'hook', 'tablet', 'parade', 'macy'],\n ['dancing', 'season', 'star', 'winner', 'riley'],\n ['browner', 'suspension', 'brandon', 'rise', 'oldboy'],\n ['daughter', 'texas', 'singer', 'killed', 'nurse']]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
